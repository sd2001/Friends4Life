{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets,transforms,models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=r'E:\\Hackerearth\\Friendship Goals\\Test Data'\n",
    "train_dir=r'E:\\Hackerearth\\Friendship Goals\\Pictures\\Train'\n",
    "val_dir=r'E:\\Hackerearth\\Friendship Goals\\Pictures\\Val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r\"E:\\Hackerearth\\Friendship Goals\\Test.csv\")\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['Adults','Teenagers','Toddler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms=transforms.Compose([transforms.Resize(256),  \n",
    "                                     torchvision.transforms.CenterCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),                                 \n",
    "                                 torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 torchvision.transforms.Normalize(mean=[0.5, 0.5,0.5],std=[0.25,0.25,0.25])])\n",
    "\n",
    "transform_val=torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=datasets.ImageFolder(train_dir,transform=train_transforms)\n",
    "train_images=DataLoader(train_images,batch_size=16,shuffle=True)\n",
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images=datasets.ImageFolder(val_dir,transform=transform_val)\n",
    "val_images=DataLoader(val_images,batch_size=16,shuffle=True)\n",
    "val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,main_dir,transform):\n",
    "        self.main_dir=main_dir\n",
    "        self.transform=transform\n",
    "        self.all_imgs=os.listdir(main_dir)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_imgs)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_loc=os.path.join(self.main_dir,self.all_imgs[idx])\n",
    "        #print(idx)\n",
    "        image=Image.open(img_loc)\n",
    "        tensor_image=self.transform(image)\n",
    "        return tensor_image,self.all_imgs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=CustomDataset(test_dir,transform=transform_val)\n",
    "test_images=DataLoader(test_loader,batch_size=16,shuffle=False)\n",
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for img,label in test_images:\n",
    "    print(img[i],label[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "num_epochs=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.last_linear=nn.Linear(in_features=512,out_features=8)\n",
    "last_layer_feat=model.fc.in_features\n",
    "model.fc=nn.Sequential(nn.Linear(last_layer_feat, 256),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.5),\n",
    "                         nn.Linear(256,len(categories)))\n",
    "                         \n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_time(model,criterion,optimizer,scheduler,num_epochs=num_epochs):\n",
    "    model.train()\n",
    "    best_model_stat=copy.deepcopy(model.state_dict())\n",
    "    best_accuracy=0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch \",epoch+1,\"/\",num_epochs,'\\t')\n",
    "        \n",
    "        running_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "        print(\"Train-Data:\")\n",
    "        for batch_idx,(inputs,labels) in enumerate(train_images):\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs=model(inputs)\n",
    "            _,preds=outputs.max(1)\n",
    "            loss=criterion(outputs,labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #scheduler.step()\n",
    "            total+=labels.size(0)\n",
    "            running_loss+=loss.item()            \n",
    "            correct+=preds.eq(labels).sum().item()\n",
    "            \n",
    "        final_loss=running_loss/(batch_idx+1)\n",
    "        acc=(correct/total)*100.00\n",
    "        \n",
    "        print('Loss : {:.4f} | Accuracy : {:.4f} | {}/{}'.format(final_loss,acc,correct,total))\n",
    "        print(\"Validation-Data\")\n",
    "        model.eval()\n",
    "        val_loss=0.0\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx,(inputs,labels) in enumerate(val_images):\n",
    "            inputs=inputs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs=model(inputs)\n",
    "            loss=criterion(outputs,labels.long())\n",
    "            val_loss+=loss.item()\n",
    "            _,preds=torch.max(outputs,1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=preds.eq(labels).sum().item()\n",
    "        final_val_loss=val_loss/(batch_idx+1)\n",
    "        val_acc=(correct/total)*100.00\n",
    "        print('Loss : {:.4f} | Accuracy : {:.4f} | {}/{}'.format(final_val_loss,val_acc,correct,total)) \n",
    "        if val_acc>best_accuracy:\n",
    "            best_accuracy=val_acc\n",
    "            best_model_stat=copy.deepcopy(model.state_dict())\n",
    "        print(\"-\"*10)\n",
    "            \n",
    "    print('Best Accuracy : {:.4f}'.format(best_accuracy))\n",
    "    model.load_state_dict(best_model_stat)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.0001,weight_decay=1e-5)\n",
    "#step_lr=lr_scheduler.StepLR(optimizer,step_size=7,gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained=training_time(model,criterion,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trained.state_dict(), r\"E:\\Hackerearth\\Friendship Goals\\friend.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained.eval()\n",
    "test_predictions=[]\n",
    "img_l=[]\n",
    "i=0\n",
    "for p,label in (test_images):\n",
    "    p=p.to(device)\n",
    "    outputs=model_trained.forward(p)\n",
    "    _, preds=outputs.max(1)    \n",
    "    test_predictions.append(preds)\n",
    "    img_l.append(label)\n",
    "img_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "for row in test_predictions:\n",
    "    for element in row:\n",
    "        final.append(element.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels=[]\n",
    "for row in img_l:\n",
    "    for element in row:\n",
    "        final_labels.append(element)\n",
    "final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_final=[]\n",
    "for name in final:\n",
    "    if name==0:\n",
    "        category_final.append('Adults')\n",
    "    elif name==1:\n",
    "        category_final.append('Teenagers')\n",
    "    elif name==2:\n",
    "        category_final.append('Toddler')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.read_csv(r'E:\\Hackerearth\\Friendship Goals\\Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Filename\"]=final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Category\"]=category_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(r'E:\\Hackerearth\\Friendship Goals\\Submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit942c60d0cc0e4cb09355ccf367753958"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
